{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e3dd9c",
   "metadata": {},
   "source": [
    "# End to end Deep Learning Project using Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f33308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as ts\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense, SimpleRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01928a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape : (25000,), Training labels shape : (25000,)\n",
      "Testing data shape : (25000,), Testing labels shape : (25000,)\n"
     ]
    }
   ],
   "source": [
    "## Load the imdb dataset\n",
    "max_features=10000 ## Vocab size\n",
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=max_features)\n",
    "\n",
    "## Print the shape of data\n",
    "print(f'Training data shape : {X_train.shape}, Training labels shape : {y_train.shape}')\n",
    "print(f'Testing data shape : {X_test.shape}, Testing labels shape : {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccd4df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my sample review (as integers) : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "This is my sample label (as integers) : 1\n"
     ]
    }
   ],
   "source": [
    "# Inspect sample reviews and its label\n",
    "sample_review=X_train[0] ## THESE ARE ONE HOT REPRESENTATION OF SENTENCE\n",
    "sample_label=y_train[0]\n",
    "\n",
    "print(f'This is my sample review (as integers) : {sample_review}')\n",
    "print(f'This is my sample label (as integers) : {sample_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ef0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping of words index back to words( fro understanding)\n",
    "word_index=imdb.get_word_index()\n",
    "reverse_word_index={values:keys for keys,values in word_index.items()}\n",
    "## interchanging key and values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31793ad",
   "metadata": {},
   "source": [
    "| **Part**                                                    | **Explanation**                                                                     |\n",
    "| ----------------------------------------------------------- | ----------------------------------------------------------------------------------- |\n",
    "| `sample_review`                                             | A list of integers representing a tokenized review.                                 |\n",
    "| `i-3`                                                       | Adjusts the index because Keras reserves 0, 1, and 2 for special tokens.            |\n",
    "| `reverse_word_index.get(i-3, '?')`                          | Looks up the word for each adjusted index. Returns `'?'` if the index is not found. |\n",
    "| `[reverse_word_index.get(i-3, '?') for i in sample_review]` | Converts all integers in the review to words.                                       |\n",
    "| `' '.join(...)`                                             | Joins the list of words into a single string with spaces.                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640a260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decorded_review=' '.join([reverse_word_index.get(i-3,'?') for i in sample_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7367cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decorded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba5c90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=500 ## max text in a single sentence\n",
    "\n",
    "X_train=sequence.pad_sequences(X_train,maxlen=max_len) ## for padding by default pre-padding\n",
    "X_test=sequence.pad_sequences(X_test,maxlen=max_len)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163d3c8",
   "metadata": {},
   "source": [
    "| **Parameter**          | **Explanation**                                                                                         |\n",
    "| ---------------------- | ------------------------------------------------------------------------------------------------------- |\n",
    "| `max_features`         | Vocabulary size: total number of unique words you're considering (e.g., 10,000 most common).            |\n",
    "| `128`                  | **Embedding dimension**: the size of the dense vector for each word (i.e., how many features per word). |\n",
    "| `input_length=max_len` | Length of input sequences (number of tokens per input).                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49afc330",
   "metadata": {},
   "source": [
    "| **Component**       | **Explanation**                                                                |\n",
    "| ------------------- | ------------------------------------------------------------------------------ |\n",
    "| `SimpleRNN`         | A type of Recurrent Neural Network layer that processes sequence data.         |\n",
    "| `128`               | Number of **RNN units** (i.e., size of the hidden state output).               |\n",
    "| `activation='relu'` | Activation function used inside the RNN unit (ReLU instead of default `tanh`). |\n",
    "\n",
    "\n",
    "\n",
    "You are creating 128 RNN units — each like a neuron that not only processes input at each time step but also keeps a memory of the previous time step (via a hidden state)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be60ea7d",
   "metadata": {},
   "source": [
    "| **Component**          | **Explanation**                                                      |\n",
    "| ---------------------- | -------------------------------------------------------------------- |\n",
    "| `Dense(1)`             | A fully connected output layer with **1 neuron**.                    |\n",
    "| `activation='sigmoid'` | Used for **binary classification** (output will be between 0 and 1). |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e02ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Desktop\\Deep Learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## train  simple rnn\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128,input_length=max_len)) # dim=128 # vocabsize=maxfeatures\n",
    "model.add(SimpleRNN(128,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8ee239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b795dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a9f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3dcf6",
   "metadata": {},
   "source": [
    "| **Parameter**                      | **Meaning / Function**                                                                                           |\n",
    "| ---------------------------------- | ---------------------------------------------------------------------------------------------------------------- |\n",
    "| `X_train`                          | Input training data (e.g., sequences of word indices).                                                           |\n",
    "| `y_train`                          | Target labels for training (e.g., 0 for negative review, 1 for positive).                                        |\n",
    "| `validation_data=(X_test, y_test)` | Data used to evaluate the model after each epoch (optional if `validation_split` is used).                       |\n",
    "| `batch_size=32`                    | Number of samples processed before the model is updated. Smaller batch = slower but often better generalization. |\n",
    "| `epochs=10`                        | Number of times the model will iterate over the entire `X_train` dataset.                                        |\n",
    "| `validation_split=0.2`             | 20% of the training data will be used as validation data **from `X_train`** (conflicts with `validation_data`).  |\n",
    "| `callbacks=[early_stopping]`       | Stop training early if performance on validation data stops improving.                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6075aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 173ms/step - accuracy: 0.6232 - loss: 5999256064.0000 - val_accuracy: 0.5748 - val_loss: 0.6612\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 163ms/step - accuracy: 0.7174 - loss: 2.7109 - val_accuracy: 0.7884 - val_loss: 0.4682\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 169ms/step - accuracy: 0.8568 - loss: 0.3613 - val_accuracy: 0.8175 - val_loss: 0.4202\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 165ms/step - accuracy: 0.8977 - loss: 0.2688 - val_accuracy: 0.8065 - val_loss: 0.4518\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 168ms/step - accuracy: 0.8963 - loss: 0.2701 - val_accuracy: 0.8041 - val_loss: 0.4539\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 171ms/step - accuracy: 0.9311 - loss: 0.1883 - val_accuracy: 0.8108 - val_loss: 0.4659\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 165ms/step - accuracy: 0.9347 - loss: 0.1860 - val_accuracy: 0.8088 - val_loss: 0.5261\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 167ms/step - accuracy: 0.9441 - loss: 0.1570 - val_accuracy: 0.8090 - val_loss: 0.5091\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,validation_data=(X_test,y_test),\n",
    "          batch_size=32,epochs=10,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a02721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "## Save my model file\n",
    "model.save('simple_rnn_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c8b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d3e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75527f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8000bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406478a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88571a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
